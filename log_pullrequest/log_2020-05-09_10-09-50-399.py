  ('/home/runner/work/mlmodels/mlmodels/mlmodels/config/test_config.json',) 
  ('test_pullrequest', 'GITHUB_REPOSITORT', 'GITHUB_SHA') 
  ('Running command', 'test_pullrequest') 





 ************************************************************************************************************************

 ******** TAG ::  {'github_repo_url': 'https://github.com/arita37/mlmodels/tree/d53e2c42d4ebc720e72bd423c3f46fa090c6a954', 'url_branch_file': 'https://github.com/arita37/mlmodels/blob/refs/heads/dev/', 'repo': 'arita37/mlmodels', 'branch': 'refs/heads/dev', 'sha': 'd53e2c42d4ebc720e72bd423c3f46fa090c6a954', 'workflow': 'test_pullrequest'}

 ******** GITHUB_WOKFLOW : https://github.com/arita37/mlmodels/actions?query=workflow%3Atest_pullrequest

 ******** GITHUB_REPO_URL : https://github.com/arita37/mlmodels/tree/d53e2c42d4ebc720e72bd423c3f46fa090c6a954

 ******** GITHUB_COMMIT_URL : https://github.com/arita37/mlmodels/commit/d53e2c42d4ebc720e72bd423c3f46fa090c6a954

 ************************************************************************************************************************
  ('/home/runner/work/mlmodels/mlmodels/pullrequest/',) 
  ('############Check model ################################',) 
  (['/home/runner/work/mlmodels/mlmodels/pullrequest/aa_mycode_test.py'],) 
  ('Used', ['/home/runner/work/mlmodels/mlmodels/pullrequest/aa_mycode_test.py']) 
  ('########### Run Check ##############################',) 





 ************************************************************************************************************************

 ******** TAG ::  {'github_repo_url': 'https://github.com/arita37/mlmodels/tree/d53e2c42d4ebc720e72bd423c3f46fa090c6a954', 'url_branch_file': 'https://github.com/arita37/mlmodels/blob/refs/heads/dev/', 'repo': 'arita37/mlmodels', 'branch': 'refs/heads/dev', 'sha': 'd53e2c42d4ebc720e72bd423c3f46fa090c6a954', 'workflow': 'test_pullrequest'}

 ******** GITHUB_WOKFLOW : https://github.com/arita37/mlmodels/actions?query=workflow%3Atest_pullrequest

 ******** GITHUB_REPO_URL : https://github.com/arita37/mlmodels/tree/d53e2c42d4ebc720e72bd423c3f46fa090c6a954

 ******** GITHUB_COMMIT_URL : https://github.com/arita37/mlmodels/commit/d53e2c42d4ebc720e72bd423c3f46fa090c6a954

 ************************************************************************************************************************





 ************************************************************************************************************************
  ('test_import',) 
['model_tf.temporal_fusion_google', 'model_tf.util', 'model_tf.__init__', 'model_tf.1_lstm', 'model_dev.__init__', 'model_sklearn.model_lightgbm', 'model_sklearn.__init__', 'model_sklearn.model_sklearn', 'preprocess.generic_old', 'preprocess.image', 'preprocess.generic', 'preprocess.tabular', 'preprocess.ztemp', 'preprocess.__init__', 'preprocess.text_torch', 'preprocess.tabular_keras', 'preprocess.timeseries', 'preprocess.text_keras', 'preprocess.text', 'model_tch.util_data', 'model_tch.pplm', 'model_tch.transformer_sentence', 'model_tch.__init__', 'model_tch.nbeats', 'model_tch.textcnn', 'model_tch.mlp', 'model_tch.pytorch_vae', 'model_tch.03_nbeats_dataloader', 'model_tch.torchhub', 'model_tch.util_transformer', 'model_tch.transformer_classifier', 'model_tch.matchzoo_models', 'model_gluon.util_autogluon', 'model_gluon.util', 'model_gluon.gluonts_model', 'model_gluon.__init__', 'model_gluon.fb_prophet', 'model_gluon.gluon_automl', 'model_flow.__init__', 'example.vision_mnist', 'example.arun_model', 'example.lightgbm_glass', 'example.benchmark_timeseries_m4', 'example.arun_hyper', 'example.benchmark_timeseries_m5', 'template.00_template_keras', 'template.model_xxx', 'model_rank.__init__', 'model_keras.charcnn', 'model_keras.charcnn_zhang', 'model_keras.namentity_crm_bilstm_dataloader', 'model_keras.01_deepctr', 'model_keras.util', 'model_keras.__init__', 'model_keras.namentity_crm_bilstm', 'model_keras.nbeats', 'model_keras.textcnn', 'model_keras.keras_gan', 'model_keras.textcnn_dataloader', 'model_keras.02_cnn', 'model_keras.preprocess', 'model_keras.Autokeras', 'model_keras.armdn', 'model_keras.textvae', 'utils.ztest_structure', 'utils.test_dataloader', 'utils.parse']
  ('Error', 'mlmodels.model_tf.temporal_fusion_google', ModuleNotFoundError("No module named 'mlmodels.mode_tf'",)) 
WARNING:tensorflow:From /opt/hostedtoolcache/Python/3.6.10/x64/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
mlmodels.model_tf.util
mlmodels.model_tf.__init__
mlmodels.model_tf.1_lstm
mlmodels.model_dev.__init__
mlmodels.model_sklearn.model_lightgbm
mlmodels.model_sklearn.__init__
mlmodels.model_sklearn.model_sklearn
mlmodels.preprocess.generic_old
mlmodels.preprocess.image
mlmodels.preprocess.generic
mlmodels.preprocess.tabular
  ('Error', 'mlmodels.preprocess.ztemp', SyntaxError('invalid character in identifier', ('/home/runner/work/mlmodels/mlmodels/mlmodels/preprocess/ztemp.py', 6, 26, 'xxx = data_info.get( ‚Äúxxx‚Äù, arg.get(‚Äúxxxx‚Äù, -1))\n'))) 
mlmodels.preprocess.__init__
mlmodels.preprocess.text_torch
mlmodels.preprocess.tabular_keras
mlmodels.preprocess.timeseries
mlmodels.preprocess.text_keras
mlmodels.preprocess.text
  ('Error', 'mlmodels.model_tch.util_data', FileNotFoundError(2, "File b'./data/train.csv' does not exist")) 
mlmodels.model_tch.pplm
mlmodels.model_tch.transformer_sentence
mlmodels.model_tch.__init__
mlmodels.model_tch.nbeats
mlmodels.model_tch.textcnn
mlmodels.model_tch.mlp
  ('Error', 'mlmodels.model_tchtorch_vae', ModuleNotFoundError("No module named 'mlmodels.model_tchtorch_vae'",)) 
  ('Error', 'mlmodels.model_tch.03_nbeats_dataloader', ModuleNotFoundError("No module named 'dataloader'",)) 
mlmodels.model_tch.torchhub
mlmodels.model_tch.util_transformer
  ('Error', 'mlmodels.model_tch.transformer_classifier', ModuleNotFoundError("No module named 'util_transformer'",)) 
mlmodels.model_tch.matchzoo_models
mlmodels.model_gluon.util_autogluon
  ('Error', 'mlmodels.model_gluon.util', TypeError('create_model() takes exactly 1 positional argument (0 given)',)) 
  ('Error', 'mlmodels.model_gluon.gluonts_model', TypeError('create_model() takes exactly 1 positional argument (0 given)',)) 
mlmodels.model_gluon.__init__
mlmodels.model_gluon.fb_prophet
mlmodels.model_gluon.gluon_automl
mlmodels.model_flow.__init__
  ('Error', 'mlmodels.example.vision_mnist', SyntaxError('invalid syntax', ('/home/runner/work/mlmodels/mlmodels/mlmodels/example/vision_mnist.py', 15, 1, '!git clone https://github.com/ahmed3bbas/mlmodels.git\n'))) 
<module 'mlmodels' from '/home/runner/work/mlmodels/mlmodels/mlmodels/__init__.py'>
/home/runner/work/mlmodels/mlmodels/mlmodels/model_keras/ardmn.json
  ('Error', 'mlmodels.example.arun_model', FileNotFoundError(2, 'No such file or directory')) 
Deprecaton set to False
/home/runner/work/mlmodels/mlmodels
  ('Error', 'mlmodels.example.lightgbm_glass', FileNotFoundError(2, 'No such file or directory')) 
mlmodels.example.benchmark_timeseries_m4
  ('Error', 'mlmodels.example.arun_hyper', NameError("name 'mlmodels' is not defined",)) 
  ('Error', 'mlmodels.example.benchmark_timeseries_m5', SyntaxError('invalid syntax', ('/home/runner/work/mlmodels/mlmodels/mlmodels/example/benchmark_timeseries_m5.py', 248, 7, 'We then reshape the forecasts into the correct data shape for submission ...\n'))) 
  ('Error', 'mlmodels.template.00_template_keras', IndentationError('expected an indented block', ('/home/runner/work/mlmodels/mlmodels/mlmodels/template/00_template_keras.py', 68, 10, '    return df, linear_cols, dnn_cols, train, test, target\n'))) 
  ('Error', 'mlmodels.template.model_xxx', NameError("name '__file___' is not defined",)) 
mlmodels.model_rank.__init__
mlmodels.model_keras.charcnn
/home/runner/work/mlmodels/mlmodels/mlmodels/dataset
mlmodels.model_keras.charcnn_zhang
mlmodels.model_keras.namentity_crm_bilstm_dataloader
mlmodels.model_keras.01_deepctr
  ('Error', 'mlmodels.model_keras.util', TypeError('create_model() takes exactly 1 positional argument (0 given)',)) 
mlmodels.model_keras.__init__
mlmodels.model_keras.namentity_crm_bilstm
mlmodels.model_keras.nbeats
mlmodels.model_keras.textcnn
  ('Error', 'mlmodels.model_keras.keras_gan', AttributeError("module 'mlmodels.model_keras.raw.keras_gan' has no attribute 'aae'",)) 
mlmodels.model_keras.textcnn_dataloader
mlmodels.model_keras.02_cnn
mlmodels.model_keras.preprocess
  ('Error', 'mlmodels.model_keras.Autokeras', ModuleNotFoundError("No module named 'autokeras'",)) 
Deprecaton set to False
  ({'model_uri': 'model_tf.1_lstm', 'learning_rate': 0.001, 'num_layers': 1, 'size': 6, 'size_layer': 128, 'output_size': 6, 'timestep': 4, 'epoch': 2}, {'data_path': '/home/runner/work/mlmodels/mlmodels/mlmodels/dataset/timeseries/GOOG-year_small.csv', 'data_type': 'pandas', 'size': [0, 0, 6], 'output_size': [0, 6]}, {'engine': 'optuna', 'method': 'prune', 'ntrials': 5}, {'engine_pars': {'engine': 'optuna', 'method': 'normal', 'ntrials': 2, 'metric_target': 'loss'}, 'learning_rate': {'type': 'log_uniform', 'init': 0.01, 'range': [0.001, 0.1]}, 'num_layers': {'type': 'int', 'init': 2, 'range': [2, 4]}, 'size': {'type': 'int', 'init': 6, 'range': [6, 6]}, 'output_size': {'type': 'int', 'init': 6, 'range': [6, 6]}, 'size_layer': {'type': 'categorical', 'value': [128, 256]}, 'timestep': {'type': 'categorical', 'value': [5]}, 'epoch': {'type': 'categorical', 'value': [2]}}) 
  (<module 'mlmodels.model_tf.1_lstm' from '/home/runner/work/mlmodels/mlmodels/mlmodels/model_tf/1_lstm.py'>,) 
  ('###### Hyper-optimization through study   ##################################',) 
  ('check', <module 'mlmodels.model_tf.1_lstm' from '/home/runner/work/mlmodels/mlmodels/mlmodels/model_tf/1_lstm.py'>, {'data_path': '/home/runner/work/mlmodels/mlmodels/mlmodels/dataset/timeseries/GOOG-year_small.csv', 'data_type': 'pandas', 'size': [0, 0, 6], 'output_size': [0, 6]}) 
[32m[I 2020-05-09 10:10:22,241][0m Finished trial#0 resulted in value: 0.4259005934000015. Current best value is 0.4259005934000015 with parameters: {'learning_rate': 0.005782684640247679, 'num_layers': 3, 'size': 6, 'output_size': 6, 'size_layer': 256, 'timestep': 5, 'epoch': 2}.[0m
{'data_path': '/home/runner/work/mlmodels/mlmodels/mlmodels/dataset/timeseries/GOOG-year_small.csv', 'data_type': 'pandas', 'size': [0, 0, 6], 'output_size': [0, 6]}
/home/runner/work/mlmodels/mlmodels/mlmodels/dataset/timeseries/GOOG-year_small.csv
         Date        Open        High  ...       Close   Adj Close   Volume
0  2016-11-02  778.200012  781.650024  ...  768.700012  768.700012  1872400
1  2016-11-03  767.250000  769.950012  ...  762.130005  762.130005  1943200
2  2016-11-04  750.659973  770.359985  ...  762.020020  762.020020  2134800
3  2016-11-07  774.500000  785.190002  ...  782.520020  782.520020  1585100
4  2016-11-08  783.400024  795.632996  ...  790.510010  790.510010  1350800

[5 rows x 7 columns]
          0         1         2         3         4         5
0  0.706562  0.629914  0.682052  0.599302  0.599302  0.153665
1  0.458824  0.320251  0.598101  0.478596  0.478596  0.174523
2  0.083484  0.331101  0.437246  0.476576  0.476576  0.230969
3  0.622851  0.723606  0.854891  0.853206  0.853206  0.069025
4  0.824209  1.000000  1.000000  1.000000  1.000000  0.000000
  ('check', <module 'mlmodels.model_tf.1_lstm' from '/home/runner/work/mlmodels/mlmodels/mlmodels/model_tf/1_lstm.py'>, {'data_path': '/home/runner/work/mlmodels/mlmodels/mlmodels/dataset/timeseries/GOOG-year_small.csv', 'data_type': 'pandas', 'size': [0, 0, 6], 'output_size': [0, 6]}) 
[32m[I 2020-05-09 10:10:24,492][0m Finished trial#1 resulted in value: 0.8908721059560776. Current best value is 0.4259005934000015 with parameters: {'learning_rate': 0.005782684640247679, 'num_layers': 3, 'size': 6, 'output_size': 6, 'size_layer': 256, 'timestep': 5, 'epoch': 2}.[0m
{'data_path': '/home/runner/work/mlmodels/mlmodels/mlmodels/dataset/timeseries/GOOG-year_small.csv', 'data_type': 'pandas', 'size': [0, 0, 6], 'output_size': [0, 6]}
/home/runner/work/mlmodels/mlmodels/mlmodels/dataset/timeseries/GOOG-year_small.csv
         Date        Open        High  ...       Close   Adj Close   Volume
0  2016-11-02  778.200012  781.650024  ...  768.700012  768.700012  1872400
1  2016-11-03  767.250000  769.950012  ...  762.130005  762.130005  1943200
2  2016-11-04  750.659973  770.359985  ...  762.020020  762.020020  2134800
3  2016-11-07  774.500000  785.190002  ...  782.520020  782.520020  1585100
4  2016-11-08  783.400024  795.632996  ...  790.510010  790.510010  1350800

[5 rows x 7 columns]
          0         1         2         3         4         5
0  0.706562  0.629914  0.682052  0.599302  0.599302  0.153665
1  0.458824  0.320251  0.598101  0.478596  0.478596  0.174523
2  0.083484  0.331101  0.437246  0.476576  0.476576  0.230969
3  0.622851  0.723606  0.854891  0.853206  0.853206  0.069025
4  0.824209  1.000000  1.000000  1.000000  1.000000  0.000000
 ################################### ('Optim, finished',) ###################################
  ('### Save Stats   ##########################################################',) 
  ('### Run Model with best   #################################################',) 
{'data_path': '/home/runner/work/mlmodels/mlmodels/mlmodels/dataset/timeseries/GOOG-year_small.csv', 'data_type': 'pandas', 'size': [0, 0, 6], 'output_size': [0, 6]}
/home/runner/work/mlmodels/mlmodels/mlmodels/dataset/timeseries/GOOG-year_small.csv
         Date        Open        High  ...       Close   Adj Close   Volume
0  2016-11-02  778.200012  781.650024  ...  768.700012  768.700012  1872400
1  2016-11-03  767.250000  769.950012  ...  762.130005  762.130005  1943200
2  2016-11-04  750.659973  770.359985  ...  762.020020  762.020020  2134800
3  2016-11-07  774.500000  785.190002  ...  782.520020  782.520020  1585100
4  2016-11-08  783.400024  795.632996  ...  790.510010  790.510010  1350800

[5 rows x 7 columns]
          0         1         2         3         4         5
0  0.706562  0.629914  0.682052  0.599302  0.599302  0.153665
1  0.458824  0.320251  0.598101  0.478596  0.478596  0.174523
2  0.083484  0.331101  0.437246  0.476576  0.476576  0.230969
3  0.622851  0.723606  0.854891  0.853206  0.853206  0.069025
4  0.824209  1.000000  1.000000  1.000000  1.000000  0.000000
  ('#### Saving     ###########################################################',) 
{'path': '/home/runner/work/mlmodels/mlmodels/mlmodels/ztest/optim_1lstm/', 'model_type': 'model_tf', 'model_uri': 'model_tf-1_lstm'}
sh: 1: ml_mlmodels: not found
mlmodels.model_keras.armdn
mlmodels.model_keras.textvae
mlmodels.utils.ztest_structure
mlmodels.utils.test_dataloader
mlmodels.utils.parse





 ************************************************************************************************************************
  ('python /home/runner/work/mlmodels/mlmodels/pullrequest/aa_mycode_test.py  2>&1 | tee -a  cd log_.txt',) 
os.getcwd /home/runner/work/mlmodels/mlmodels
############ Your custom code ################################



 python /home/runner/work/mlmodels/mlmodels/mlmodels/optim.py  
Deprecaton set to False
  ({'model_uri': 'model_tf.1_lstm', 'learning_rate': 0.001, 'num_layers': 1, 'size': 6, 'size_layer': 128, 'output_size': 6, 'timestep': 4, 'epoch': 2}, {'data_path': '/home/runner/work/mlmodels/mlmodels/mlmodels/dataset/timeseries/GOOG-year_small.csv', 'data_type': 'pandas', 'size': [0, 0, 6], 'output_size': [0, 6]}, {'engine': 'optuna', 'method': 'prune', 'ntrials': 5}, {'engine_pars': {'engine': 'optuna', 'method': 'normal', 'ntrials': 2, 'metric_target': 'loss'}, 'learning_rate': {'type': 'log_uniform', 'init': 0.01, 'range': [0.001, 0.1]}, 'num_layers': {'type': 'int', 'init': 2, 'range': [2, 4]}, 'size': {'type': 'int', 'init': 6, 'range': [6, 6]}, 'output_size': {'type': 'int', 'init': 6, 'range': [6, 6]}, 'size_layer': {'type': 'categorical', 'value': [128, 256]}, 'timestep': {'type': 'categorical', 'value': [5]}, 'epoch': {'type': 'categorical', 'value': [2]}}) 
  (<module 'mlmodels.model_tf.1_lstm' from '/home/runner/work/mlmodels/mlmodels/mlmodels/model_tf/1_lstm.py'>,) 
  ('###### Hyper-optimization through study   ##################################',) 
  ('check', <module 'mlmodels.model_tf.1_lstm' from '/home/runner/work/mlmodels/mlmodels/mlmodels/model_tf/1_lstm.py'>, {'data_path': '/home/runner/work/mlmodels/mlmodels/mlmodels/dataset/timeseries/GOOG-year_small.csv', 'data_type': 'pandas', 'size': [0, 0, 6], 'output_size': [0, 6]}) 
  (<mlmodels.model_tf.1_lstm.Model object at 0x7feca6d22278>,) 
[32m[I 2020-05-09 10:10:32,036][0m Finished trial#0 resulted in value: 0.6898738294839859. Current best value is 0.6898738294839859 with parameters: {'learning_rate': 0.004520065975371598, 'num_layers': 4, 'size': 6, 'output_size': 6, 'size_layer': 128, 'timestep': 5, 'epoch': 2}.[0m
{'data_path': '/home/runner/work/mlmodels/mlmodels/mlmodels/dataset/timeseries/GOOG-year_small.csv', 'data_type': 'pandas', 'size': [0, 0, 6], 'output_size': [0, 6]}
/home/runner/work/mlmodels/mlmodels/mlmodels/dataset/timeseries/GOOG-year_small.csv
         Date        Open        High  ...       Close   Adj Close   Volume
0  2016-11-02  778.200012  781.650024  ...  768.700012  768.700012  1872400
1  2016-11-03  767.250000  769.950012  ...  762.130005  762.130005  1943200
2  2016-11-04  750.659973  770.359985  ...  762.020020  762.020020  2134800
3  2016-11-07  774.500000  785.190002  ...  782.520020  782.520020  1585100
4  2016-11-08  783.400024  795.632996  ...  790.510010  790.510010  1350800

[5 rows x 7 columns]
          0         1         2         3         4         5
0  0.706562  0.629914  0.682052  0.599302  0.599302  0.153665
1  0.458824  0.320251  0.598101  0.478596  0.478596  0.174523
2  0.083484  0.331101  0.437246  0.476576  0.476576  0.230969
3  0.622851  0.723606  0.854891  0.853206  0.853206  0.069025
4  0.824209  1.000000  1.000000  1.000000  1.000000  0.000000
  ('check', <module 'mlmodels.model_tf.1_lstm' from '/home/runner/work/mlmodels/mlmodels/mlmodels/model_tf/1_lstm.py'>, {'data_path': '/home/runner/work/mlmodels/mlmodels/mlmodels/dataset/timeseries/GOOG-year_small.csv', 'data_type': 'pandas', 'size': [0, 0, 6], 'output_size': [0, 6]}) 
  (<mlmodels.model_tf.1_lstm.Model object at 0x7fecc3866550>,) 
[32m[I 2020-05-09 10:10:33,835][0m Finished trial#1 resulted in value: 0.33464832603931427. Current best value is 0.33464832603931427 with parameters: {'learning_rate': 0.002123762303299581, 'num_layers': 3, 'size': 6, 'output_size': 6, 'size_layer': 256, 'timestep': 5, 'epoch': 2}.[0m
{'data_path': '/home/runner/work/mlmodels/mlmodels/mlmodels/dataset/timeseries/GOOG-year_small.csv', 'data_type': 'pandas', 'size': [0, 0, 6], 'output_size': [0, 6]}
/home/runner/work/mlmodels/mlmodels/mlmodels/dataset/timeseries/GOOG-year_small.csv
         Date        Open        High  ...       Close   Adj Close   Volume
0  2016-11-02  778.200012  781.650024  ...  768.700012  768.700012  1872400
1  2016-11-03  767.250000  769.950012  ...  762.130005  762.130005  1943200
2  2016-11-04  750.659973  770.359985  ...  762.020020  762.020020  2134800
3  2016-11-07  774.500000  785.190002  ...  782.520020  782.520020  1585100
4  2016-11-08  783.400024  795.632996  ...  790.510010  790.510010  1350800

[5 rows x 7 columns]
          0         1         2         3         4         5
0  0.706562  0.629914  0.682052  0.599302  0.599302  0.153665
1  0.458824  0.320251  0.598101  0.478596  0.478596  0.174523
2  0.083484  0.331101  0.437246  0.476576  0.476576  0.230969
3  0.622851  0.723606  0.854891  0.853206  0.853206  0.069025
4  0.824209  1.000000  1.000000  1.000000  1.000000  0.000000
 ################################### ('Optim, finished',) ###################################
  ('### Save Stats   ##########################################################',) 
  ('### Run Model with best   #################################################',) 
{'data_path': '/home/runner/work/mlmodels/mlmodels/mlmodels/dataset/timeseries/GOOG-year_small.csv', 'data_type': 'pandas', 'size': [0, 0, 6], 'output_size': [0, 6]}
/home/runner/work/mlmodels/mlmodels/mlmodels/dataset/timeseries/GOOG-year_small.csv
         Date        Open        High  ...       Close   Adj Close   Volume
0  2016-11-02  778.200012  781.650024  ...  768.700012  768.700012  1872400
1  2016-11-03  767.250000  769.950012  ...  762.130005  762.130005  1943200
2  2016-11-04  750.659973  770.359985  ...  762.020020  762.020020  2134800
3  2016-11-07  774.500000  785.190002  ...  782.520020  782.520020  1585100
4  2016-11-08  783.400024  795.632996  ...  790.510010  790.510010  1350800

[5 rows x 7 columns]
          0         1         2         3         4         5
0  0.706562  0.629914  0.682052  0.599302  0.599302  0.153665
1  0.458824  0.320251  0.598101  0.478596  0.478596  0.174523
2  0.083484  0.331101  0.437246  0.476576  0.476576  0.230969
3  0.622851  0.723606  0.854891  0.853206  0.853206  0.069025
4  0.824209  1.000000  1.000000  1.000000  1.000000  0.000000
  ('#### Saving     ###########################################################',) 
{'path': '/home/runner/work/mlmodels/mlmodels/mlmodels/ztest/optim_1lstm/', 'model_type': 'model_tf', 'model_uri': 'model_tf-1_lstm'}



 python /home/runner/work/mlmodels/mlmodels/mlmodels/model_keras/textcnn.py    
  ('#### Loading params   ##############################################',) 
  ('#### Path params   ##########################################',) 
  ('#### Loading dataset   #############################################',) 
Loading data...
Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz

    8192/17464789 [..............................] - ETA: 0s
 2220032/17464789 [==>...........................] - ETA: 0s
 9232384/17464789 [==============>...............] - ETA: 0s
16261120/17464789 [==========================>...] - ETA: 0s
17465344/17464789 [==============================] - 0s 0us/step
Pad sequences (samples x time)...
  ('#### Model init, fit   #############################################',) 
Using TensorFlow backend.
WARNING:tensorflow:From /opt/hostedtoolcache/Python/3.6.10/x64/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:From /opt/hostedtoolcache/Python/3.6.10/x64/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /opt/hostedtoolcache/Python/3.6.10/x64/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 40)           0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 40, 50)       250         input_1[0][0]                    
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 38, 128)      19328       embedding_1[0][0]                
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 37, 128)      25728       embedding_1[0][0]                
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 36, 128)      32128       embedding_1[0][0]                
__________________________________________________________________________________________________
global_max_pooling1d_1 (GlobalM (None, 128)          0           conv1d_1[0][0]                   
__________________________________________________________________________________________________
global_max_pooling1d_2 (GlobalM (None, 128)          0           conv1d_2[0][0]                   
__________________________________________________________________________________________________
global_max_pooling1d_3 (GlobalM (None, 128)          0           conv1d_3[0][0]                   
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 384)          0           global_max_pooling1d_1[0][0]     
                                                                 global_max_pooling1d_2[0][0]     
                                                                 global_max_pooling1d_3[0][0]     
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            385         concatenate_1[0][0]              
==================================================================================================
Total params: 77,819
Trainable params: 77,819
Non-trainable params: 0
__________________________________________________________________________________________________
Loading data...
Pad sequences (samples x time)...
Train on 25000 samples, validate on 25000 samples
Epoch 1/1

 1000/25000 [>.............................] - ETA: 13s - loss: 7.5900 - accuracy: 0.5050
 2000/25000 [=>............................] - ETA: 10s - loss: 7.7203 - accuracy: 0.4965
 3000/25000 [==>...........................] - ETA: 8s - loss: 7.7637 - accuracy: 0.4937 
 4000/25000 [===>..........................] - ETA: 7s - loss: 7.7510 - accuracy: 0.4945
 5000/25000 [=====>........................] - ETA: 7s - loss: 7.7832 - accuracy: 0.4924
 6000/25000 [======>.......................] - ETA: 6s - loss: 7.8378 - accuracy: 0.4888
 7000/25000 [=======>......................] - ETA: 6s - loss: 7.8353 - accuracy: 0.4890
 8000/25000 [========>.....................] - ETA: 5s - loss: 7.7586 - accuracy: 0.4940
 9000/25000 [=========>....................] - ETA: 5s - loss: 7.7723 - accuracy: 0.4931
10000/25000 [===========>..................] - ETA: 5s - loss: 7.7939 - accuracy: 0.4917
11000/25000 [============>.................] - ETA: 4s - loss: 7.7851 - accuracy: 0.4923
12000/25000 [=============>................] - ETA: 4s - loss: 7.7816 - accuracy: 0.4925
13000/25000 [==============>...............] - ETA: 3s - loss: 7.7846 - accuracy: 0.4923
14000/25000 [===============>..............] - ETA: 3s - loss: 7.7729 - accuracy: 0.4931
15000/25000 [=================>............] - ETA: 3s - loss: 7.7494 - accuracy: 0.4946
16000/25000 [==================>...........] - ETA: 2s - loss: 7.7395 - accuracy: 0.4952
17000/25000 [===================>..........] - ETA: 2s - loss: 7.7234 - accuracy: 0.4963
18000/25000 [====================>.........] - ETA: 2s - loss: 7.6922 - accuracy: 0.4983
19000/25000 [=====================>........] - ETA: 1s - loss: 7.6731 - accuracy: 0.4996
20000/25000 [=======================>......] - ETA: 1s - loss: 7.6728 - accuracy: 0.4996
21000/25000 [========================>.....] - ETA: 1s - loss: 7.6549 - accuracy: 0.5008
22000/25000 [=========================>....] - ETA: 0s - loss: 7.6610 - accuracy: 0.5004
23000/25000 [==========================>...] - ETA: 0s - loss: 7.6606 - accuracy: 0.5004
24000/25000 [===========================>..] - ETA: 0s - loss: 7.6685 - accuracy: 0.4999
25000/25000 [==============================] - 10s 395us/step - loss: 7.6666 - accuracy: 0.5000 - val_loss: 7.6246 - val_accuracy: 0.5000
  ('#### save the trained model  #######################################',) 
{'path': '/home/runner/work/mlmodels/mlmodels/mlmodels/ztest/model_keras/textcnn/model.h5', 'model_path': '/home/runner/work/mlmodels/mlmodels/mlmodels/ztest/model_keras/textcnn/model.h5'}
  ('#### Predict   #####################################################',) 
Loading data...
  ('#### metrics   #####################################################',) 
{}
  ('#### Plot   ########################################################',) 
  ('#### Save/Load   ###################################################',) 
WARNING:tensorflow:From /opt/hostedtoolcache/Python/3.6.10/x64/lib/python3.6/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
{'path': '/home/runner/work/mlmodels/mlmodels/mlmodels/ztest/model_keras/textcnn/model.h5', 'model_path': '/home/runner/work/mlmodels/mlmodels/mlmodels/ztest/model_keras/textcnn/model.h5'}
{'path': '/home/runner/work/mlmodels/mlmodels/mlmodels/ztest/model_keras/textcnn/model.h5', 'model_path': '/home/runner/work/mlmodels/mlmodels/mlmodels/ztest/model_keras/textcnn/model.h5'}
(<mlmodels.util.Model_empty object at 0x7f65bc0f7710>, None)
  ('#### Module init   ############################################',) 
  (<module 'mlmodels.model_keras.textcnn' from '/home/runner/work/mlmodels/mlmodels/mlmodels/model_keras/textcnn.py'>,) 
  ('#### Loading params   ##############################################',) 
  ('#### Path params   ##########################################',) 
  ('#### Model init   ############################################',) 
Model: "model_2"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            (None, 40)           0                                            
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 40, 50)       250         input_2[0][0]                    
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 38, 128)      19328       embedding_2[0][0]                
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 37, 128)      25728       embedding_2[0][0]                
__________________________________________________________________________________________________
conv1d_6 (Conv1D)               (None, 36, 128)      32128       embedding_2[0][0]                
__________________________________________________________________________________________________
global_max_pooling1d_4 (GlobalM (None, 128)          0           conv1d_4[0][0]                   
__________________________________________________________________________________________________
global_max_pooling1d_5 (GlobalM (None, 128)          0           conv1d_5[0][0]                   
__________________________________________________________________________________________________
global_max_pooling1d_6 (GlobalM (None, 128)          0           conv1d_6[0][0]                   
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 384)          0           global_max_pooling1d_4[0][0]     
                                                                 global_max_pooling1d_5[0][0]     
                                                                 global_max_pooling1d_6[0][0]     
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1)            385         concatenate_2[0][0]              
==================================================================================================
Total params: 77,819
Trainable params: 77,819
Non-trainable params: 0
__________________________________________________________________________________________________
  (<mlmodels.model_keras.textcnn.Model object at 0x7f65925ace80>,) 
  ('#### Fit   ########################################################',) 
Loading data...
Pad sequences (samples x time)...
Train on 25000 samples, validate on 25000 samples
Epoch 1/1

 1000/25000 [>.............................] - ETA: 12s - loss: 7.8660 - accuracy: 0.4870
 2000/25000 [=>............................] - ETA: 9s - loss: 7.7203 - accuracy: 0.4965 
 3000/25000 [==>...........................] - ETA: 8s - loss: 7.8148 - accuracy: 0.4903
 4000/25000 [===>..........................] - ETA: 7s - loss: 7.7855 - accuracy: 0.4922
 5000/25000 [=====>........................] - ETA: 7s - loss: 7.6881 - accuracy: 0.4986
 6000/25000 [======>.......................] - ETA: 6s - loss: 7.7305 - accuracy: 0.4958
 7000/25000 [=======>......................] - ETA: 6s - loss: 7.7126 - accuracy: 0.4970
 8000/25000 [========>.....................] - ETA: 5s - loss: 7.7222 - accuracy: 0.4964
 9000/25000 [=========>....................] - ETA: 5s - loss: 7.7075 - accuracy: 0.4973
10000/25000 [===========>..................] - ETA: 4s - loss: 7.6804 - accuracy: 0.4991
11000/25000 [============>.................] - ETA: 4s - loss: 7.6638 - accuracy: 0.5002
12000/25000 [=============>................] - ETA: 4s - loss: 7.6462 - accuracy: 0.5013
13000/25000 [==============>...............] - ETA: 3s - loss: 7.6442 - accuracy: 0.5015
14000/25000 [===============>..............] - ETA: 3s - loss: 7.6184 - accuracy: 0.5031
15000/25000 [=================>............] - ETA: 3s - loss: 7.6319 - accuracy: 0.5023
16000/25000 [==================>...........] - ETA: 2s - loss: 7.6360 - accuracy: 0.5020
17000/25000 [===================>..........] - ETA: 2s - loss: 7.6684 - accuracy: 0.4999
18000/25000 [====================>.........] - ETA: 2s - loss: 7.6419 - accuracy: 0.5016
19000/25000 [=====================>........] - ETA: 1s - loss: 7.6416 - accuracy: 0.5016
20000/25000 [=======================>......] - ETA: 1s - loss: 7.6582 - accuracy: 0.5005
21000/25000 [========================>.....] - ETA: 1s - loss: 7.6586 - accuracy: 0.5005
22000/25000 [=========================>....] - ETA: 0s - loss: 7.6638 - accuracy: 0.5002
23000/25000 [==========================>...] - ETA: 0s - loss: 7.6593 - accuracy: 0.5005
24000/25000 [===========================>..] - ETA: 0s - loss: 7.6679 - accuracy: 0.4999
25000/25000 [==============================] - 10s 386us/step - loss: 7.6666 - accuracy: 0.5000 - val_loss: 7.6246 - val_accuracy: 0.5000
  ('#### Predict   ####################################################',) 
Loading data...
(array([[1.],
       [1.],
       [1.],
       ...,
       [1.],
       [1.],
       [1.]], dtype=float32), None)
  ('#### Get  metrics   ################################################',) 
  ('#### Save   ########################################################',) 
  ('#### Load   ########################################################',) 
  ('############ Model preparation   ##################################',) 
  ('#### Module init   ############################################',) 
  (<module 'mlmodels.model_keras.textcnn' from '/home/runner/work/mlmodels/mlmodels/mlmodels/model_keras/textcnn.py'>,) 
  ('#### Loading params   ##############################################',) 
  ('#### Path params   ##########################################',) 
  ('#### Model init   ############################################',) 
Model: "model_3"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 40)           0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 40, 50)       250         input_3[0][0]                    
__________________________________________________________________________________________________
conv1d_7 (Conv1D)               (None, 38, 128)      19328       embedding_3[0][0]                
__________________________________________________________________________________________________
conv1d_8 (Conv1D)               (None, 37, 128)      25728       embedding_3[0][0]                
__________________________________________________________________________________________________
conv1d_9 (Conv1D)               (None, 36, 128)      32128       embedding_3[0][0]                
__________________________________________________________________________________________________
global_max_pooling1d_7 (GlobalM (None, 128)          0           conv1d_7[0][0]                   
__________________________________________________________________________________________________
global_max_pooling1d_8 (GlobalM (None, 128)          0           conv1d_8[0][0]                   
__________________________________________________________________________________________________
global_max_pooling1d_9 (GlobalM (None, 128)          0           conv1d_9[0][0]                   
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 384)          0           global_max_pooling1d_7[0][0]     
                                                                 global_max_pooling1d_8[0][0]     
                                                                 global_max_pooling1d_9[0][0]     
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1)            385         concatenate_3[0][0]              
==================================================================================================
Total params: 77,819
Trainable params: 77,819
Non-trainable params: 0
__________________________________________________________________________________________________
  ('############ Model fit   ##########################################',) 
Loading data...
Pad sequences (samples x time)...
Train on 25000 samples, validate on 25000 samples
Epoch 1/1

 1000/25000 [>.............................] - ETA: 13s - loss: 7.2986 - accuracy: 0.5240
 2000/25000 [=>............................] - ETA: 9s - loss: 7.6130 - accuracy: 0.5035 
 3000/25000 [==>...........................] - ETA: 8s - loss: 7.6155 - accuracy: 0.5033
 4000/25000 [===>..........................] - ETA: 7s - loss: 7.7011 - accuracy: 0.4978
 5000/25000 [=====>........................] - ETA: 7s - loss: 7.6544 - accuracy: 0.5008
 6000/25000 [======>.......................] - ETA: 6s - loss: 7.7203 - accuracy: 0.4965
 7000/25000 [=======>......................] - ETA: 6s - loss: 7.7542 - accuracy: 0.4943
 8000/25000 [========>.....................] - ETA: 5s - loss: 7.6896 - accuracy: 0.4985
 9000/25000 [=========>....................] - ETA: 5s - loss: 7.6496 - accuracy: 0.5011
10000/25000 [===========>..................] - ETA: 4s - loss: 7.6452 - accuracy: 0.5014
11000/25000 [============>.................] - ETA: 4s - loss: 7.6527 - accuracy: 0.5009
12000/25000 [=============>................] - ETA: 4s - loss: 7.6666 - accuracy: 0.5000
13000/25000 [==============>...............] - ETA: 3s - loss: 7.6525 - accuracy: 0.5009
14000/25000 [===============>..............] - ETA: 3s - loss: 7.6611 - accuracy: 0.5004
15000/25000 [=================>............] - ETA: 3s - loss: 7.6390 - accuracy: 0.5018
16000/25000 [==================>...........] - ETA: 2s - loss: 7.6551 - accuracy: 0.5008
17000/25000 [===================>..........] - ETA: 2s - loss: 7.6765 - accuracy: 0.4994
18000/25000 [====================>.........] - ETA: 2s - loss: 7.6803 - accuracy: 0.4991
19000/25000 [=====================>........] - ETA: 1s - loss: 7.6731 - accuracy: 0.4996
20000/25000 [=======================>......] - ETA: 1s - loss: 7.6643 - accuracy: 0.5002
21000/25000 [========================>.....] - ETA: 1s - loss: 7.6601 - accuracy: 0.5004
22000/25000 [=========================>....] - ETA: 0s - loss: 7.6757 - accuracy: 0.4994
23000/25000 [==========================>...] - ETA: 0s - loss: 7.6813 - accuracy: 0.4990
24000/25000 [===========================>..] - ETA: 0s - loss: 7.6737 - accuracy: 0.4995
25000/25000 [==============================] - 10s 389us/step - loss: 7.6666 - accuracy: 0.5000 - val_loss: 7.6246 - val_accuracy: 0.5000
fit success None
  ('############ Prediction############################################',) 
Loading data...
(array([[1.],
       [1.],
       [1.],
       ...,
       [1.],
       [1.],
       [1.]], dtype=float32), None)
  ('############ Save/ Load ############################################',) 
Using TensorFlow backend.
/opt/hostedtoolcache/Python/3.6.10/x64/lib/python3.6/site-packages/mxnet/optimizer/optimizer.py:167: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB
  Optimizer.opt_registry[name].__name__))
/home/runner/work/mlmodels/mlmodels/mlmodels/model_gluon/gluonts_model.py:569: DeprecationWarning: invalid escape sequence \s
  """
/home/runner/work/mlmodels/mlmodels/mlmodels/model_keras/raw/char_cnn/data_utils.py:45: DeprecationWarning:

invalid escape sequence \s

